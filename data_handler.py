import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import requests
from io import StringIO
from datetime import datetime
from datetime import timedelta
import matplotlib.pyplot as plt
import numpy as np


class DataHandler:
    def __init__(self, url):
        self.url = url
        self.data = None

    def download_data(self):
        response = requests.get(self.url)
        self.data = pd.read_csv(StringIO(response.text))
        return self.data

    def feature_engineering(self):
        # Rolling mean and standard deviation
        self.data['ROLLING_MEAN_5'] = self.data['LAST_PRICE'].rolling(window=5).mean()
        self.data['ROLLING_STD_5'] = self.data['LAST_PRICE'].rolling(window=5).std()

        # Lagged Features
        for i in range(1, 4):  # Adding lags for the past 3 time steps
            self.data[f'LAG_{i}'] = self.data['LAST_PRICE'].shift(i)

        # MACD
        self.data['EMA12'] = self.data['LAST_PRICE'].ewm(span=12).mean()
        self.data['EMA26'] = self.data['LAST_PRICE'].ewm(span=26).mean()
        self.data['MACD'] = self.data['EMA12'] - self.data['EMA26']

        # RSI
        delta = self.data['LAST_PRICE'].diff()
        gain = (delta.where(delta > 0, 0)).fillna(0)
        loss = (-delta.where(delta < 0, 0)).fillna(0)
        avg_gain = gain.rolling(window=14).mean()
        avg_loss = loss.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        self.data['RSI'] = 100 - (100 / (1 + rs))

        # Drop NA values generated by rolling functions and technical indicators
        self.data.dropna(inplace=True)

        return self.data

    def preprocess_data(self):
        # Data Cleaning: Remove any extra quotes and convert to float
        for col in self.data.columns:
            self.data[col] = self.data[col].map(lambda x: float(x.replace('"', '')) if isinstance(x, str) else x)
        
        # Feature Engineering
        self.feature_engineering()
    
        # Separate the target column
        target = self.data['LAST_PRICE']
        self.data = self.data.drop(['LAST_PRICE', 'TIME'], axis=1)  # Assuming 'TIME' is the timestamp and not used as a feature for training
    
        # Normalize the features
        scaler = MinMaxScaler(feature_range=(0, 1))
        data_normalized = scaler.fit_transform(self.data)
    
        # Normalize the target
        target_scaler = MinMaxScaler(feature_range=(0, 1))
        target_normalized = target_scaler.fit_transform(target.values.reshape(-1, 1))
    
        return data_normalized, target_normalized, scaler, target_scaler

    def create_sequences(self, data, target, seq_length, steps_ahead=60):
        X, y = [], []
        for i in range(len(data) - seq_length - steps_ahead + 1):
            X.append(data[i:i+seq_length])
            y.append(target[i+seq_length:i+seq_length+steps_ahead])
        return np.array(X), np.array(y)
